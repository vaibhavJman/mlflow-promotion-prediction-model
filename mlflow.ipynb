{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --pre mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_01 =  pd.read_csv('./final_training_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Split the Final Dataset into Features and Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_data_01.drop('PromotionStatus', axis=1)   # Features\n",
    "y = training_data_01['PromotionStatus']                # Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Split the Dataset into Training and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 17)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %pip install imbalanced-learn\n",
    "# \n",
    "X_test.shape\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    OverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14262, 17)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Experiment-1 \n",
    "    RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[ 239   50    0]\n",
      " [  48 1084   57]\n",
      " [   0   80  442]]\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       289\n",
      "           1       0.89      0.91      0.90      1189\n",
      "           2       0.89      0.85      0.87       522\n",
      "\n",
      "    accuracy                           0.88      2000\n",
      "   macro avg       0.87      0.86      0.87      2000\n",
      "weighted avg       0.88      0.88      0.88      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = {\"random_state\":42 ,\"n_estimators\": 100,\"max_depth\":10}\n",
    "\n",
    "model = RandomForestClassifier(**params)  \n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Confusion Matrix\\n\",confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report\\n\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.863  0.843  0.868  0.86   0.8665]\n",
      "Mean accuracy: 0.8600999999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5) \n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Create dictionary of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "report_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Log the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/29 12:01:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/29 12:01:21 INFO mlflow.tracking._tracking_service.client: üèÉ View run Random Forest Classifier with SMOTE at: http://127.0.0.1:5000/#/experiments/140846681390198027/runs/78cc9fa06282497b96b8be4d2dca8f5f.\n",
      "2024/10/29 12:01:21 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/140846681390198027.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"First Experiment\")\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=\"Random Forest Classifier with SMOTE\"):\n",
    "    mlflow.set_tag(\"Training Info\", \"Trained with Project final Data\")\n",
    "    # mlflow.log_params({'random_state': 42})\n",
    "    \n",
    "    mlflow.log_params(params=params)\n",
    "\n",
    "    mlflow.log_metrics({\n",
    "        'accuracy': report_dict['accuracy'],\n",
    "        'recall_class_0': report_dict['0']['recall'],\n",
    "        'recall_class_1': report_dict['1']['recall'],\n",
    "        'recall_class_2': report_dict['2']['recall'],\n",
    "        'precision_class_0':report_dict['0']['precision'],\n",
    "        'precision_class_1':report_dict['1']['precision'],\n",
    "        'precision_class_2':report_dict['2']['precision'],\n",
    "        'f1_score_macro': report_dict['macro avg']['f1-score']\n",
    "    })\n",
    "    # mlflow.log_metric('Cross-validation scores',scores)\n",
    "    mlflow.log_metric('cross_val_mean_accuracy', scores.mean())\n",
    "\n",
    "    model_info=  mlflow.sklearn.log_model(model, \"Random Forest Classifier with SMOTE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Load our saved model as a Python Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Load Model from the Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs:/78cc9fa06282497b96b8be4d2dca8f5f/Random Forest Classifier with SMOTE\n"
     ]
    }
   ],
   "source": [
    "# loaded_model_1 = mlflow.pyfunc.load_model(\"file:///c:/Assessments/final_project/Data_Science/mlruns/140846681390198027/6d3fc1e2dac64a0db9e272d9b3fd82cc/artifacts/Random Forest Classifier\")\n",
    "loaded_model_2 = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "print(model_info.model_uri) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Use our model to predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[ 239   50    0]\n",
      " [  48 1084   57]\n",
      " [   0   80  442]]\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       289\n",
      "           1       0.89      0.91      0.90      1189\n",
      "           2       0.89      0.85      0.87       522\n",
      "\n",
      "    accuracy                           0.88      2000\n",
      "   macro avg       0.87      0.86      0.87      2000\n",
      "weighted avg       0.88      0.88      0.88      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = loaded_model_2.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix\\n\",confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report\\n\",classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Register Out Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Random Forest Classifier with SMOTE'.\n",
      "2024/10/29 11:57:23 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Random Forest Classifier with SMOTE, version 1\n",
      "Created version '1' of model 'Random Forest Classifier with SMOTE'.\n"
     ]
    }
   ],
   "source": [
    "#Method-1\n",
    "model_name = \"Random Forest Classifier with SMOTE\"\n",
    "result = mlflow.register_model(\n",
    "    model_info.model_uri, model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'Random Forest Classifier with SMOTE' already exists. Creating a new version of this model...\n",
      "2024/10/29 12:17:48 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Random Forest Classifier with SMOTE, version 2\n",
      "Created version '2' of model 'Random Forest Classifier with SMOTE'.\n"
     ]
    }
   ],
   "source": [
    "#Method-2\n",
    "model_name = \"Random Forest Classifier with SMOTE\"\n",
    "run_id = input(\"Enter Run ID\")\n",
    "model_uri = f\"runs:/{run_id}/{model_name}\"\n",
    "\n",
    "result = mlflow.register_model(\n",
    "            model_uri, model_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Load Models from the Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Random Forest Classifier with SMOTE\"\n",
    "model_version = 2 \n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "# model_uri = f\"models:/{model_name}@challenger\"\n",
    "\n",
    "\n",
    "loaded_model_3= mlflow.sklearn.load_model(model_uri)\n",
    "y_pred = loaded_model_3.predict(X_test)\n",
    "\n",
    "# print(y[:4])\n",
    "\n",
    "print(\"Confusion Matrix\\n\",confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report\\n\",classification_report(y_test, y_pred))\n",
    "\n",
    "print(loaded_model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Development Environment to Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Employee Promotion Prediction'.\n",
      "Copied version '2' of model 'Random Forest Classifier with SMOTE' to version '1' of model 'Employee Promotion Prediction'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1730184923906, current_stage='None', description='', last_updated_timestamp=1730184923906, name='Employee Promotion Prediction', run_id='78cc9fa06282497b96b8be4d2dca8f5f', run_link='', source='models:/Random Forest Classifier with SMOTE/2', status='READY', status_message='', tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dev_model_uri = f\"models:/{model_name}@challenger\"\n",
    "prod_model = \"Employee Promotion Prediction\"\n",
    "client = mlflow.MlflowClient()\n",
    "client.copy_model_version(src_model_uri= dev_model_uri ,dst_name = prod_model )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Set version and alias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=['challenger'], creation_timestamp=1730184468931, current_stage='None', description='', last_updated_timestamp=1730184468931, name='Random Forest Classifier with SMOTE', run_id='78cc9fa06282497b96b8be4d2dca8f5f', run_link='', source=('file:///c:/Assessments/final_project/Data_Science/mlruns/140846681390198027/78cc9fa06282497b96b8be4d2dca8f5f/artifacts/Random '\n",
       " 'Forest Classifier with SMOTE'), status='READY', status_message='', tags={}, user_id='', version='2'>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "vr = client.get_model_version(\"Random Forest Classifier with SMOTE\", 2)\n",
    "# print(vr)\n",
    "client.set_registered_model_alias(\"Random Forest Classifier with SMOTE\", \"challenger\",vr.version)\n",
    "# client.delete_registered_model_alias(\"Random Forest Classifier with SMOTE\", \"challenger\")\n",
    "\n",
    "client.get_model_version_by_alias(\"Random Forest Classifier with SMOTE\", \"challenger\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Experiment-2 \n",
    "    Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_01 =  pd.read_csv('./final_training_data.csv')\n",
    "\n",
    "X = training_data_01.drop('PromotionStatus', axis=1) \n",
    "y = training_data_01['PromotionStatus'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_resampled = scaler.fit_transform(X_train_resampled)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 287    2    0]\n",
      " [   7 1180    2]\n",
      " [   0    2  520]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       289\n",
      "           1       1.00      0.99      0.99      1189\n",
      "           2       1.00      1.00      1.00       522\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       0.99      0.99      0.99      2000\n",
      "weighted avg       0.99      0.99      0.99      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=15000)  \n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Log different Models\n",
    "    Track Experiments using MLFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\n",
    "        \"Random Forest Classifier\",\n",
    "        {\"random_state\":42, \"max_depth\":10,\"n_estimators\" :100},\n",
    "        RandomForestClassifier(),\n",
    "        (X_train_resampled,y_train_resampled),\n",
    "        (X_test,y_test)\n",
    "     ) ,\n",
    "     \n",
    "     (\n",
    "        \"Logistic Regression Model with StandardScaler\",\n",
    "        {\"max_iter\":1000 },\n",
    "        LogisticRegression(),\n",
    "        (X_train_resampled,y_train_resampled),\n",
    "        (X_test,y_test)    \n",
    "     )\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = []\n",
    "\n",
    "for model_name,params, model, train_set, test_set in models:\n",
    "    X_train = train_set[0]\n",
    "    y_train = train_set[1]\n",
    "    X_test = test_set[0]\n",
    "    y_test = test_set[1]\n",
    "\n",
    "    model.set_params(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test,y_pred, output_dict=True)\n",
    "    reports.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'0': {'precision': 0.8327526132404182,\n",
       "   'recall': 0.8269896193771626,\n",
       "   'f1-score': 0.8298611111111112,\n",
       "   'support': 289.0},\n",
       "  '1': {'precision': 0.8929159802306426,\n",
       "   'recall': 0.911690496215307,\n",
       "   'f1-score': 0.9022055763628797,\n",
       "   'support': 1189.0},\n",
       "  '2': {'precision': 0.8857715430861723,\n",
       "   'recall': 0.8467432950191571,\n",
       "   'f1-score': 0.8658178256611165,\n",
       "   'support': 522.0},\n",
       "  'accuracy': 0.8825,\n",
       "  'macro avg': {'precision': 0.8704800455190776,\n",
       "   'recall': 0.861807803537209,\n",
       "   'f1-score': 0.8659615043783692,\n",
       "   'support': 2000.0},\n",
       "  'weighted avg': {'precision': 0.8823576756058485,\n",
       "   'recall': 0.8825,\n",
       "   'f1-score': 0.882254598200839,\n",
       "   'support': 2000.0}},\n",
       " {'0': {'precision': 0.9761904761904762,\n",
       "   'recall': 0.9930795847750865,\n",
       "   'f1-score': 0.9845626072041166,\n",
       "   'support': 289.0},\n",
       "  '1': {'precision': 0.9966216216216216,\n",
       "   'recall': 0.992430613961312,\n",
       "   'f1-score': 0.9945217024863042,\n",
       "   'support': 1189.0},\n",
       "  '2': {'precision': 0.9961685823754789,\n",
       "   'recall': 0.9961685823754789,\n",
       "   'f1-score': 0.9961685823754789,\n",
       "   'support': 522.0},\n",
       "  'accuracy': 0.9935,\n",
       "  'macro avg': {'precision': 0.9896602267291922,\n",
       "   'recall': 0.9938929270372925,\n",
       "   'f1-score': 0.9917509640219665,\n",
       "   'support': 2000.0},\n",
       "  'weighted avg': {'precision': 0.9935510778635778,\n",
       "   'recall': 0.9935,\n",
       "   'f1-score': 0.9935124488691027,\n",
       "   'support': 2000.0}}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/29 11:13:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/29 11:13:34 INFO mlflow.tracking._tracking_service.client: üèÉ View run Random Forest Classifier at: http://127.0.0.1:5000/#/experiments/887698436236583196/runs/7096e08a354748349509bd97fe85bddc.\n",
      "2024/10/29 11:13:34 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/887698436236583196.\n",
      "2024/10/29 11:13:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/29 11:13:41 INFO mlflow.tracking._tracking_service.client: üèÉ View run Logistic Regression Model with StandardScaler at: http://127.0.0.1:5000/#/experiments/887698436236583196/runs/24b16c0cf29c492482baddcbbe5a09f1.\n",
      "2024/10/29 11:13:41 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/887698436236583196.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment(\"Log Differetn Models\")\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n",
    "\n",
    "for i, element in enumerate(models):\n",
    "    model_name = element[0]\n",
    "    params = element[1]\n",
    "    model = element[2]\n",
    "    report = reports[i]\n",
    "\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # mlflow.set_tag(\"Training Info\", \"Trained with Project final Data\")\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        mlflow.log_metrics({\n",
    "        'accuracy': report['accuracy'],\n",
    "        'recall_class_0': report['0']['recall'],\n",
    "        'recall_class_1': report['1']['recall'],\n",
    "        'recall_class_2': report['2']['recall'],\n",
    "        'precision_class_0':report['0']['precision'],\n",
    "        'precision_class_1':report['1']['precision'],\n",
    "        'precision_class_2':report['2']['precision'],\n",
    "        'f1_score_macro': report['macro avg']['f1-score']\n",
    "        })\n",
    "\n",
    "\n",
    "        # mlflow.log_metric('accuracy',report['accuracy'])\n",
    "        # mlflow.log_metric('Cross-validation scores',scores)\n",
    "        # mlflow.log_metric('cross_val_mean_accuracy', scores.mean())\n",
    "\n",
    "        model_info  =  mlflow.sklearn.log_model(model, model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
